{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to AI Wednesday \u2728","text":"<p>AI Wednesday is a weekly, community-driven gathering at TinkerSpace, focused on exploring, understanding, and building with Artificial Intelligence. It brings together students, makers, developers, designers, and curious minds who want to learn AI by doing, not just listening.</p> <p>Each session may have a planned topic, project sharing, or demo, or it may evolve organically based on the questions and interests of the people who show up. The format stays flexible to encourage open discussion, hands-on experimentation, and collaborative learning.</p> <p>Whether you\u2019re curious about how AI works, experimenting with tools like LLMs, building small prototypes, or just starting out, AI Wednesday is an open space to learn, question, and build together.</p>"},{"location":"#contributors-community","title":"Contributors &amp; Community","text":"<p>AI Wednesday is run by the community, for the community. It grows through people who share their ideas, experiments, and time.</p>"},{"location":"#contributors","title":"Contributors","text":"<ul> <li>Session hosts and topic leads  </li> <li>Project and demo presenters  </li> <li>Workshop or activity facilitators  </li> </ul>"},{"location":"#community-members","title":"Community Members","text":"<ul> <li>Mentors and practitioners  </li> <li>Regular participants  </li> <li>First-time learners and explorers  </li> </ul> <p>Interested in contributing or hosting a session? Reach out to the organizers or propose a topic during the meetup.</p> <p>This space documents weekly AI Wednesday sessions, including topics discussed, projects shared, and key learnings from each week.</p>"},{"location":"#supported-by","title":"Supported By","text":"TinkerHub"},{"location":"blog/","title":"AI Wednesday Journal","text":""},{"location":"blog/2026/01/10/ai-wednesday-01/","title":"AI-Wednesday 01: Creating the 2026 plan for AI Wednesday while reflecting on the past year activities and improvement areas","text":"<p>AI Wednesday saw a successful run in 2025, marking a huge jump in both the consistency and quality of sessions taken. Among the 53 total sessions taken, 31 of them were taken this year with around 188 unique attendees and 12 Organisers</p> <p>Though consistency during the later half of 2025 has improved, the major challenge remains the less number of hosts to take the sessions. The focus on the topics for the sessions have also switched to a much detailed approach leading to a higher involvement of more serious participants.</p>"},{"location":"blog/2026/01/10/ai-wednesday-01/#summary-report","title":"Summary report","text":"<p>2025 marked a turning point for AI Wednesday - not just in numbers, but in purpose. What began as a space to casually exchange updates on AI trends gradually evolved into a focused learning-driven community. Early sessions leaned toward showcasing projects, discussing breakthroughs, and exploring newly released tools. These conversations helped build momentum and attracted a diverse group of curious minds, but as the year progressed, a deeper realization emerged: attendees weren\u2019t just looking to know what\u2019s new - they wanted to understand how things work.</p> <p>This shift shaped the second half of the year. Sessions became more structured, topic-driven, and intentional. Instead of broad overviews, each AI Wednesday began centering around a single concept that participants could meaningfully take away - something they could later explore, build upon, or apply. Knowledge became the north star. As a result, engagement deepened, discussions became more thoughtful, and participants walked away feeling that their time had genuinely added value to their learning journey.</p> <p></p> <p>Complex and high-impact topics such as Agentic AI and MCP were explored in depth, sometimes spanning multiple sessions to do justice to the subject. This approach not only improved conceptual clarity but also encouraged continuity - participants returned week after week to build on what they had learned earlier. The community itself grew stronger through this consistency, drawing in a wide demographic ranging from school students to experienced working professionals, all united by a shared intent: to learn AI seriously and meaningfully.</p> <p>By the end of 2025, AI Wednesday had matured from a discussion forum into a learning ecosystem\u2014one that values depth over hype, understanding over surface-level trends, and community-driven growth over passive consumption. This foundation now sets the stage for a more ambitious and impactful 2026.</p>"},{"location":"blog/2026/01/10/ai-wednesday-01/#future-plans","title":"Future plans","text":"<p>During the review and planning discussion, we aligned on the following actions for the coming year:</p> <ul> <li>Topic Planning: Topics should be expanded to include more in depth learning of the theoretical basics like machine Learning and Deep Learning, rather than sticking to mostly Generative AI.</li> <li>Documentation: From 2026 onwards, every AI Wednesday will be documented. The host is responsible for a short journal entry, following simple guidelines, giving visibility to both the host and the community.</li> <li>Intro to AI: A pre-curated session would be held every month called Introduction to AI where beginners can get their initial exposure to what AI is and the basics of computing.</li> <li>Practical Projects: Encourage a more practical approach to learning AI, with topics such as local hosting and inference and Edge AI.</li> <li>Physical AI Collaboration: Work with Maker Thursday to explore Physical AI, focusing on AI running on hardware, while setting up a project that can be displayed on Tinkerspace.</li> <li>Inference Guide: Explore and curate a guide that updates the cost of AI inference with suggestions on use cases for leading models.</li> </ul>"},{"location":"blog/2026/01/10/documentation-guide/","title":"How to Document an AI Wednesday Session","text":"<p>AI Wednesday is a weekly, community driven gathering at TinkerSpace where people connect, share, and build.</p> <p>From 2026 onwards, every session should have a short journal entry, usually written by the host.</p>"},{"location":"blog/2026/01/10/documentation-guide/#why-we-document-ai-wednesday","title":"Why we document AI Wednesday","text":"<p>AI Wednesday is a weekly community gathering, but the conversations, demos, and learnings should not end when the session ends.</p> <p>By documenting each AI Wednesday, we:</p> <ul> <li>Keep a clear log of what was discussed and built</li> <li>Help members who could not attend stay updated</li> <li>Make it easy for new members to understand the community\u2019s direction</li> <li>Create a shared reference for ideas, projects, and follow ups</li> <li>Build a long term archive of our community journey</li> </ul> <p>These short journal entries are not meant to be detailed reports. They are lightweight snapshots of each session, written so that any community member can quickly read, catch up, and continue the conversation.</p>"},{"location":"blog/2026/01/10/documentation-guide/#documentation-steps","title":"Documentation steps","text":"<ol> <li>Set up MkDocs Material on your computer</li> <li>Run the site locally</li> <li>Add a new journal post using the template</li> <li>Push changes and raise a pull request</li> </ol>"},{"location":"blog/2026/01/10/documentation-guide/#setup-on-your-computer","title":"Setup on your computer","text":"<p>First, you need setup the computer to run the <code>mkdocs</code> locally.</p>"},{"location":"blog/2026/01/10/documentation-guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>Install Python and pip - follow the guide here</li> <li>Install MkDocs - follow the guide here.</li> <li>Install Git - follow the guide here</li> </ul>"},{"location":"blog/2026/01/10/documentation-guide/#fork-clone-and-run-locally","title":"Fork, clone, and run locally","text":"<ol> <li> <p>Fork the repository</p> </li> <li> <p>Open the upstream repository: tinkerhub/AIWednesday</p> </li> <li> <p>Click Fork (creates your copy under your GitHub account)</p> </li> <li> <p>Clone your fork</p> </li> </ol> <pre><code>git clone https://github.com/tinkerhub/AIWednesday.git\ncd AIWednesday\n</code></pre> <ol> <li>Start the local dev server</li> </ol> <p>Run this from the folder that contains <code>mkdocs.yml</code>:</p> <pre><code>mkdocs serve\n</code></pre> <p>MkDocs will serve the site locally (usually on <code>http://127.0.0.1:8000/</code>)</p>"},{"location":"blog/2026/01/10/documentation-guide/#create-a-new-ai-wednesday-journal-entry","title":"Create a new AI Wednesday journal entry","text":"<p>The site journal is powered by the Material blog feature (you can see it live at /blog/)</p> <ol> <li>Create a new branch</li> </ol> <pre><code>git checkout -b add-AIWednesday-journal-YYYY-MM-DD\n</code></pre> <ol> <li>Add a new post file</li> </ol> <p>Follow the existing pattern in the repository for where posts live.</p> <ul> <li> <p><code>docs/blog/posts/YYYY-MM-DD-title.md</code></p> </li> <li> <p>Add front matter</p> </li> </ul> <p>Add metadata for your Journal post,</p> <pre><code>---\ntitle: 'AI Wednesday XX : Name for the AI Wednesday'\ndate: YYYY-MM-DD\nauthors: [autor]\nslug: ai-wednesday-xx\ndescription: &gt;\n  A Small Description\n---\n</code></pre> <p>If this is your first time contributing, please add your details to the authors file before submitting your post.</p> <p>open the file <code>docs/blog/authors.yml</code> and add new entry</p> <pre><code>  author-username:\n    name: Author Full Name\n    description: Author tag line\n    avatar: https://avatars.githubusercontent.com/u/xxxxxxxx\n    url: Tinkerhub App profile URL\n\n</code></pre> <p>In the avatar section, replace the <code>xxxxxxx</code> to your github profile id.</p>"},{"location":"blog/2026/01/10/documentation-guide/#journal-template-copy-paste","title":"Journal template (copy paste)","text":"<p>Use this template inside your post:</p> <pre><code>---\ntitle: 'AI Wednesday XX : Name for the AI Wednesday'\ndate: YYYY-MM-DD\nauthors: [autor]\nslug: ai-wednesday-xx\ndescription: &gt;\n  A Small Description\n---\n\n## Overview\nWrite 3 to 6 lines on what happened this week. Mention the theme and the general vibe.\n\n## Topics\n- Topic 1\n- Topic 2\n- Topic 3\n\n## Project Presentation\n- Name \u2013 project title (one line summary if needed)\n- Name \u2013 project title\n\n## Photos\n### Group photo\n![Group photo](../assets/XX/group-photo.jpg)\n\n### Activity photo\n![Activity photo](../assets/XX/activity-photo.jpg)\n\n## Highlights\n- One key takeaway (learning, decision, win, or community moment)\n\n## Next Week\n- Topic: TBD\n- Host: TBD\n\n</code></pre>"},{"location":"blog/2026/01/10/documentation-guide/#notes-for-photos","title":"Notes for photos:","text":"<ul> <li>Keep filenames simple and consistent.</li> <li>Store images in the same place the repo already uses for images.</li> <li>Always add meaningful alt text.</li> </ul>"},{"location":"blog/2026/01/10/documentation-guide/#preview-your-changes","title":"Preview your changes","text":"<p>While mkdocs serve is running, open the local site and check:</p> <ul> <li>The post appears in the journal list.</li> <li>Images load.</li> <li>Headings look correct and spacing is clean.</li> </ul>"},{"location":"blog/2026/01/10/documentation-guide/#commit-push-and-open-a-pull-request","title":"Commit, push, and open a pull request","text":"<ol> <li>Commit and push to your fork</li> </ol> <pre><code>git add .\ngit commit -m \"Add AI Wednesday journal for YYYY-MM-DD\"\ngit push -u origin add-AIWednesday-journal-YYYY-MM-DD\n</code></pre> <ol> <li>Create a pull request to upstream</li> </ol> <p>On GitHub, open your fork and you should see a prompt to create a PR. GitHub\u2019s flow for PRs from forks is documented here</p> <p>PR checklist:</p> <ul> <li>Title includes the date and session name.</li> <li>Post follows the minimum structure.</li> <li>Photos included or clearly marked pending.</li> <li>Previewed locally.</li> </ul> <p>Suggested style (keep it consistent)</p> <ul> <li>Prefer short paragraphs and bullet lists.</li> <li>Avoid long intros.</li> <li>Name people and projects clearly (credit matters).</li> <li>If something is TBD, write \u201cTBD\u201d instead of leaving it blank.</li> </ul>"},{"location":"blog/2026/01/14/ai-wednesday-02/","title":"AI Wednesday 02 : Under the Hood of Modern LLMs","text":""},{"location":"blog/2026/01/14/ai-wednesday-02/#overview","title":"Overview","text":"<p>This week\u2019s AI Wednesday session was about understanding how modern AI models like ChatGPT actually work behind the scenes. Instead of treating AI as something magical or human-like, we broke it down into simpler ideas and mechanisms.</p> <p>We started by clearing a common misconception that these models \u201cthink\u201d or \u201cunderstand\u201d things. The discussion focused on how LLMs are trained to predict the next piece of text, and how doing this at a very large scale creates the illusion of intelligence.</p> <p>The session was mostly conceptual and discussion-driven. The goal was not to teach people how to build models, but to help everyone develop a clear mental model of what is happening inside these systems.</p>"},{"location":"blog/2026/01/14/ai-wednesday-02/#topics","title":"Topics","text":"<ul> <li>Why LLMs do not think like humans and what they actually do instead</li> <li>What \u201cnext token prediction\u201d means in simple terms</li> <li>How text is broken into tokens and converted into numbers</li> <li>What embeddings are and how they represent meaning</li> <li>A brief look at how language models evolved from simple word prediction to transformers</li> <li>What attention is and why transformers made modern AI possible</li> <li>Some important limitations of LLMs and why they sometimes fail</li> </ul>"},{"location":"blog/2026/01/14/ai-wednesday-02/#photos","title":"Photos","text":""},{"location":"blog/2026/01/14/ai-wednesday-02/#highlights","title":"Highlights","text":"<ul> <li>A major takeaway was realizing that modern AI feels intelligent not because it understands, but because it has learned patterns from huge amounts of human language.</li> </ul>"},{"location":"blog/2026/01/14/ai-wednesday-02/#next-week","title":"Next Week","text":"<ul> <li>Topic: VL-JEPA</li> <li>Host: Devadath</li> </ul>"},{"location":"blog/2026/01/21/ai-wednesday-03/","title":"AI Wednesday 03 : VL-JEPA- Vision Language Joint Embedding Predictive Architecture","text":""},{"location":"blog/2026/01/21/ai-wednesday-03/#overview","title":"Overview","text":"<p>This week\u2019s AI-Wednesday we focused on VL-JEPA, a new kind of vision-language architecture and how it differs from the vision-language models (VLMs) most people are familiar with.</p> <p>We started by explaining what VLM and VLA models are and how they generally work, so everyone could get a basic understanding first. Then we moved into VL-JEPA, its main idea, and why it works differently from traditional models. We also discussed how this approach can be useful for robots and real-world tasks. The session was very curious and interactive, with some great discussions.</p>"},{"location":"blog/2026/01/21/ai-wednesday-03/#topics","title":"Topics","text":""},{"location":"blog/2026/01/21/ai-wednesday-03/#traditional-vision-language-models-vlms","title":"Traditional Vision-Language Models (VLMs):","text":"<ul> <li>We kicked off by revisiting how standard vision-language models work, especially models that process images and text together and generate text token by token, to ensure everyone understood the baseline architecture and limitations</li> </ul>"},{"location":"blog/2026/01/21/ai-wednesday-03/#introducing-vl-jepa-joint-embedding-predictive-architecture","title":"Introducing VL-JEPA &amp; Joint Embedding Predictive Architecture:","text":"<ul> <li>We then explored VL-JEPA\u2019s core idea: instead of autoregressive token generation, it predicts continuous semantic embeddings in a shared latent space. This enables stronger performance with fewer parameters and better efficiency on tasks like classification and retrieval.</li> </ul>"},{"location":"blog/2026/01/21/ai-wednesday-03/#real-world-impacts-robotics-relevance","title":"Real-World Impacts &amp; Robotics Relevance:","text":"<ul> <li>Finally, we discussed how VL-JEPA\u2019s non-generative, predictive design could be especially valuable in robotics and embodied AI enabling systems to anticipate meaning and actions from sensory data rather than just generating descriptions, which could make perception and decision-making workflows much more efficient on robots.</li> </ul>"},{"location":"blog/2026/01/21/ai-wednesday-03/#photos","title":"Photos","text":""},{"location":"blog/2026/01/21/ai-wednesday-03/#highlights","title":"Highlights","text":"<ul> <li>One key takeaway from the session was understanding how VL-JEPA predicts meaning instead of tokens like other traditional models.</li> </ul>"},{"location":"blog/2026/01/21/ai-wednesday-03/#next-week","title":"Next Week","text":"<ul> <li>Topic: Intro To Edge AI</li> <li>Host: Sebin Thomas</li> </ul>"},{"location":"blog/archive/2026/","title":"2026","text":""}]}